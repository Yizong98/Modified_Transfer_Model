{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import load_model\n",
    "import audio_processor as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(\"mini_test/*.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mini_test\\Chopin - Andante spinato.mp3\n",
      "data/mini_test\\Chopin - Ballade in A flat major op.47 no.3.mp3\n",
      "data/mini_test\\Chopin - Ballade in F major op.38 No. 2.mp3\n",
      "data/mini_test\\Chopin - Ballade in G minor, op.23 no.1.mp3\n",
      "data/mini_test\\ChopinFuneralMarch.mp3\n",
      "data/mini_test\\ChopinFuneralMarch2.mp3\n",
      "data/mini_test\\ChopinHeroicPolonaise.mp3\n",
      "data/mini_test\\ChopinMinuteWaltz.mp3\n",
      "data/mini_test\\ChopinNocturneinGminor.mp3\n",
      "data/mini_test\\ChopinPianoNocturninEbm.mp3\n",
      "data/mini_test\\ChopinRomanticPiano.mp3\n",
      "data/mini_test\\Kevin Kern - Because I Love You.mp3\n",
      "data/mini_test\\Kevin Kern - dance.mp3\n",
      "data/mini_test\\Kevin Kern - go the green.mp3\n",
      "data/mini_test\\Kevin Kern - Le Jardin.mp3\n",
      "data/mini_test\\Kevin Kern - secret.mp3\n",
      "data/mini_test\\Kevin Kern - sun.mp3\n",
      "data/mini_test\\Kevin Kern - The Touch Of Love.mp3\n",
      "data/mini_test\\Kevin Kern - wave.mp3\n",
      "data/mini_test\\Kevin Kern - We Should Waltz.mp3\n"
     ]
    }
   ],
   "source": [
    "for i in glob.glob(\"data/mini_test/*.mp3\"):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "melgrams = np.zeros((0, 1, 96, 1366))\n",
    "for i in glob.glob(\"data/mini_test/*.mp3\"):\n",
    "    melgram = ap.compute_melgram(i)\n",
    "    melgrams = np.concatenate((melgrams, melgram), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "melgrams = melgrams.transpose(0,2,3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 2\n",
    "num_of_samples = 20\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "labels[0:10]=0\n",
    "labels[10:]=1\n",
    "names = ['Chopin','Other']\n",
    "Y = np_utils.to_categorical(labels, num_of_classes)\n",
    "x,y = shuffle(melgrams,Y, random_state=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "trans_model = load_model('transfer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 96, 1366, 1)       0         \n",
      "_________________________________________________________________\n",
      "bn_0_freq (BatchNormalizatio (None, 96, 1366, 1)       384       \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 96, 1366, 32)      320       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 96, 1366, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu_46 (ELU)                 (None, 96, 1366, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 341, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 341, 64)       18496     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 48, 341, 64)       256       \n",
      "_________________________________________________________________\n",
      "elu_47 (ELU)                 (None, 48, 341, 64)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 24, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 24, 85, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 24, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_48 (ELU)                 (None, 24, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 12, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 12, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 12, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_49 (ELU)                 (None, 12, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 4, 4, 32)          18464     \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "elu_50 (ELU)                 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 114,194\n",
      "Trainable params: 113,490\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trans_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_10:0\", shape=(?, 96, 1366, 1), dtype=float32) at layer \"input_10\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2e0e10c1a8d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mflat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'flatten'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_layear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'output_layer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcustom_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmelgrams_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m   1809\u001b[0m                                 \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1810\u001b[0m                                 \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1811\u001b[1;33m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1812\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_10:0\", shape=(?, 96, 1366, 1), dtype=float32) at layer \"input_10\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "num_of_classes = 2\n",
    "num_of_samples = 20\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "labels[0:10]=0\n",
    "labels[10:]=1\n",
    "names = ['Chopin','Other']\n",
    "Y = np_utils.to_categorical(labels, num_of_classes)\n",
    "x,y = shuffle(melgrams,Y, random_state=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "last_layear = trans_model.get_layer('pool3').output\n",
    "flat = Flatten(name='flatten')(last_layear)\n",
    "out = Dense(num_of_classes, activation='softmax', name='output_layer')(flat)\n",
    "custom_model = Model(inputs=melgrams_input,outputs= out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 96, 1366, 1)       0         \n",
      "_________________________________________________________________\n",
      "bn_0_freq (BatchNormalizatio (None, 96, 1366, 1)       384       \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 96, 1366, 32)      320       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 96, 1366, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu_46 (ELU)                 (None, 96, 1366, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 341, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 341, 64)       18496     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 48, 341, 64)       256       \n",
      "_________________________________________________________________\n",
      "elu_47 (ELU)                 (None, 48, 341, 64)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 24, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 24, 85, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 24, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_48 (ELU)                 (None, 24, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 12, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 12, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 12, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_49 (ELU)                 (None, 12, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 4, 4, 32)          18464     \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "elu_50 (ELU)                 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 114,194\n",
      "Trainable params: 113,490\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trans_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "melgrams_input = Input(shape=(96,1366,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_2:0' shape=(?, 96, 1366, 1) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melgrams_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_10:0\", shape=(?, 96, 1366, 1), dtype=float32) at layer \"input_10\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-86d2c27f28b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mflat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'flatten'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_layear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'output_layer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcustom_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmelgrams_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yizong\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m   1809\u001b[0m                                 \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1810\u001b[0m                                 \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1811\u001b[1;33m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1812\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_10:0\", shape=(?, 96, 1366, 1), dtype=float32) at layer \"input_10\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "last_layear = trans_model.get_layer('pool5').output\n",
    "flat = Flatten(name='flatten')(last_layear)\n",
    "out = Dense(num_of_classes, activation='softmax', name='output_layer')(flat)\n",
    "custom_model = Model(melgrams_input,outputs= out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
